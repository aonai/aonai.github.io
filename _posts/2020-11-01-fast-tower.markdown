---
title: Fast Tower
intro: Using a Baxter robot to build a tower of cups.
layout: default
# modal-id: 1
date: 2020-11-01
time: November, 2020
video: https://www.youtube.com/embed/HEcnxoLQmnU
img: 10-cups-whole.gif
urls:
    - 
        url: https://drive.google.com/drive/folders/1TNZ8SyosjOLlZyvqhP1VXR4JyEkqHliD?usp=sharing
        url-description: Other Video Demos
        url-icon: fa-folder
    - 
        url: https://github.com/aonai/final-project-fast-tower.git
        url-description: Source Code
        url-icon: fa-github
members: Dimitrios Chamzas, Dongho Kang, Gabbie Wink
skills: Baxter, ROS, MoveIt!, Apriltag
description: This project is the final project of Embedded Systems in Robotics. Its goal is to control a Baxter robot to stack a fixed number of cups into a tower. The tower is built on a table that is placed in front of Baxter. The source code includes several different nodes to operate Baxter with or without computer vision and to build a tower out of 3, 6, and 10 cups. More detailed descriptions can be found on the project's GitHub page. To minimize challenges from vision detection and precise manipulation, this project is separated into two tasks. Starting with random cups placed in the middle of the table, task 1 needs to grab and place them at each side of the table in order. Then, task2 needs to grab the sorted cups and place them back in the middle of the table to stack them into a tower. To avoid collision between the two arms, these two tasks are executed alternatively. Once one arm completes placing a cup, it should move away from the middle of the table and leave workspace for the other arm. The image below shows how a table is divided into the working area and sorted area.  <img src="img/portfolio/fast-tower-table.png"> For this project, my main job is to control both arms of Baxter to let them grab and place cups from one to another specified location. The locations are either pre-defined or provided by Apriltags depending on whether the node uses computer vision. The image below exhibits the logic of the robot's behaviors. <img src="img/portfolio/grab_and_place.png" style="width:80%" float="center"><br> The image on the left below shows Baxter grabbing a sorted cup. The image on the right below shows Baxter placing the cup into the workstation. The movement of Baxter arm is controlled using ROS <a target="_blank" rel="noopener noreferrer" href="http://docs.ros.org/en/hydro/api/baxter_interface/html/baxter_interface.gripper.Gripper-class.html#version_check">MoveIt</a> package for Baxter. The gripper is controlled using <a target="_blank" rel="noopener noreferrer" href="http://docs.ros.org/en/hydro/api/baxter_interface/html/baxter_interface.gripper.Gripper-class.html#version_check">Baxter ROS interface</a>. <img src="img/portfolio/fast-tower-single-grab.gif" style="width:40%" float="left">  <img src="img/portfolio/fast-tower-single-place.gif" style="width:41%" float="left"> The team mainly uses cartesian planning methods provided by MoveIt to control behavior of the arms and add a short settlement time in between each move. As shown in the image below, initially, the node will execute pose planning to get a better result if the output of cartesian planning is insufficient to complete a task (if the fraction of a computed path is less than 30%). <img src="img/portfolio/execute_cartesian.png" style="width:90%" float="center"><br> However, path planning with pose target sometimes result in unexpected behavior. For instance, Baxter may rotate its arm by a full circle even if the task is to move a cup horizontally from left to right. Also, planners may give a trajectory path too close to MoveIt objects leading to a collision at reality. This problem is fixed by adding more larger thresholds at MoveIt. Nonetheless, these thresholds need to be smaller to allow proper collision detection for attaching cup objects inside rviz. Rather than finding the right thresholds for all parameters, the team decides to generate all movements of Baxter only using cartesian planning. The revised code diagram is shown in the image below. <br><img src="img/portfolio/execute_cartesian_2.png" style="width:50%; margin-left:20%;"> <br>Tasks completed by other team members include gazebo simulation, computer vision using AprilTags, and integration of all components. Please refer to the project's GitHub page for more information. 
---
